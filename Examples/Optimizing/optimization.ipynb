{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing an ACT-R Model\n",
    "\n",
    "Here, we will see how to optimize an ACT-R model using Python libraries for scientific computing. We will use John Anderson's model of the Fan Effect from ACT-R's tutorial, Unit 5. First, let's load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import actr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The fan model\n",
    "\n",
    "John Anderson's fan model is explained in detailed in the ACT-R tutorial, Unit 5. There are actually different versions of the model. The code used here is a modified version of the model called `fan-no-pm-model.lisp`, which does not use any Perceptual/Motor interface (and, therefore, requires no device). This is just to make it easy to interact with the code.\n",
    "\n",
    "### Splitting the model\n",
    "\n",
    "In this notebook, we will optimize the values of four parameters, `:LF`, `:MAS`, `:GA`, and `:IMAGINAL-ACTIVATION`. Being _decalarative_ parameters, they cannot be changed after chunks have been loaded into the model. So, we will actually split the model code into two parts. One file, `fan-no-pm-main.lisp`, contains the man model code, while the other file `fan-no-pm-chunks.lisp`, contains the declarative memory chunks. This permits us to execute the load the model in two steps, and modify the parameters in the middle.\n",
    "\n",
    "### Model performance in the fan experiment\n",
    "\n",
    "One of the quirks of this model is that there is no _noise_ whatsoever, so it does not require more than one run per condition. That means that precise estimates can be obtained by running only 18 trials of the model, one for each level of the fan effect (Fan of 1, 2, 3), from each source of activation (Person or Location), and for each item type (Target or Foil). For each possible combination of these factors, the function `sentence` sets the corresponding stimulus into the goal buffer and lets the model retrieve a response and record the answer. \n",
    "\n",
    "The function `sentence` takes 8 arguments, the first four of which specify the stimulus type (person fan, location fan, foil or target, and retrieval strategy) and the last four specificy the values of the four parameters that we want to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence (person, location, target, term, \n",
    "              lf = 0.63, mas = 1.6, ga = 2.0, ia = 1.0):\n",
    "    actr.load_act_r_model(\"fan-no-pm-main.lisp\")\n",
    "\n",
    "    actr.set_parameter_value(\":lf\", lf)\n",
    "    actr.set_parameter_value(\":mas\", mas)\n",
    "    actr.set_parameter_value(\":ga\", ga)\n",
    "    actr.set_parameter_value(\":imaginal-activation\", ia)\n",
    "    \n",
    "    actr.load_act_r_code(\"fan-no-pm-chunks.lisp\")\n",
    "    \n",
    "    if term == 'person':\n",
    "        actr.pdisable(\"retrieve-from-location\")\n",
    "    else:\n",
    "        actr.pdisable(\"retrieve-from-person\")\n",
    "\n",
    "    # Instead of presenting the items visibly \n",
    "    # just modify the chunk which will be placed \n",
    "    # into the goal buffer when the model runs.\n",
    "\n",
    "    actr.mod_chunk(\"goal\", \"arg1\", person, \"arg2\", location, \"state\", \"test\")\n",
    "\n",
    "    response_time = actr.run(30)[0]\n",
    "    response = actr.chunk_slot_value(actr.buffer_read(\"goal\"),\"state\")\n",
    "\n",
    "\n",
    "    # Return the list of the time and whether \n",
    "    # the correct answer was given.\n",
    "      \n",
    "    if target:\n",
    "        if response.lower() == \"'k'\".lower():\n",
    "            return (response_time ,True)\n",
    "        else:\n",
    "            return (response_time ,False)\n",
    "    else:\n",
    "        if response.lower() == \"'d'\".lower():\n",
    "            return (response_time ,True)\n",
    "        else:\n",
    "            return (response_time ,False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions provide a handy way to simulate an an entire experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_person_location(term, lf, mas, ga, ia):\n",
    "    data = []\n",
    "    for person,location,target in [(\"'lawyer'\", \"'store'\", True),\n",
    "                                   (\"'captain'\", \"'cave'\", True),\n",
    "                                   (\"'hippie'\", \"'church'\", True),\n",
    "                                   (\"'debutante'\", \"'bank'\", True),\n",
    "                                   (\"'earl'\", \"'castle'\", True),\n",
    "                                   (\"'hippie'\", \"'bank'\", True),\n",
    "                                   (\"'fireman'\", \"'park'\", True),\n",
    "                                   (\"'captain'\", \"'park'\", True),\n",
    "                                   (\"'hippie'\", \"'park'\", True),\n",
    "                                   (\"'fireman'\", \"'store'\", False),\n",
    "                                   (\"'captain'\", \"'store'\", False),\n",
    "                                   (\"'giant'\", \"'store'\", False),\n",
    "                                   (\"'fireman'\", \"'bank'\", False),\n",
    "                                   (\"'captain'\", \"'bank'\", False),\n",
    "                                   (\"'giant'\", \"'bank'\", False),\n",
    "                                   (\"'lawyer'\", \"'park'\", False),\n",
    "                                   (\"'earl'\", \"'park'\", False),\n",
    "                                   (\"'giant'\", \"'park'\", False)]:\n",
    "\n",
    "        data.append(sentence(person, location, target, term, \n",
    "                             lf, mas, ga, ia))\n",
    "\n",
    "    return data\n",
    "\n",
    "  \n",
    "def experiment():\n",
    "    output_person_location(list(map(lambda x,y:((x[0]+y[0])/2,(x[1] and y[1])),\n",
    "                                    do_person_location('person'),\n",
    "                                    do_person_location('location'))))\n",
    "    \n",
    "def output_person_location(data):\n",
    "    \"\"\"Prints the Person/Location data as a nice Fan Effect table\"\"\"\n",
    "    rts = list(map(lambda x: x[0],data))\n",
    "    actr.correlation(rts,person_location_data)\n",
    "    actr.mean_deviation(rts,person_location_data)\n",
    "\n",
    "    print(\"\\nTARGETS:\\n                         Person fan\")\n",
    "    print(\"  Location      1             2             3\")\n",
    "    print(\"    fan\")\n",
    "    \n",
    "    for i in range(3):\n",
    "        print(\"     %d      \" % (i+1),end=\"\")\n",
    "        for j in range(3):\n",
    "            print(\"%6.3f (%-5s)\" % (data[j + (i * 3)]),end=\"\")\n",
    "        print()\n",
    "\n",
    "    print()\n",
    "    print(\"FOILS:\")\n",
    "    for i in range(3):\n",
    "        print(\"     %d      \" % (i+1),end=\"\")\n",
    "        for j in range(3):\n",
    "            print(\"%6.3f (%-5s)\" % (data[j + ((i + 3) * 3)]),end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "Now, with the code in place to run the model, we can start thinking about optimizing it. First, we need to define our _ground truth_, that is, the empirical data we want to compare our model against. Here is the data from John Anderson's 1974 Fan Effect experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_location_data = [1.11, 1.17, 1.22,\n",
    "                        1.17, 1.20, 1.22,\n",
    "                        1.15, 1.23, 1.36,\n",
    "                        1.20, 1.22, 1.26,\n",
    "                        1.25, 1.36, 1.29,\n",
    "                        1.26, 1.47, 1.47]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The objective function\n",
    "We define the _objective function_ we want to _minimize_. In this case, the RMSE between predicted data (the model) and the observed data (the experiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fan_rmse(lf, mas, ga, ia):\n",
    "    \"\"\"Calculates RMSE for Fan Effect data (objective fun to minimize)\"\"\"\n",
    "    L = list(map(lambda x,y:((x[0]+y[0])/2,(x[1] and y[1])),\n",
    "                        do_person_location('person', lf, mas, ga, ia),\n",
    "                        do_person_location('location', lf, mas, ga, ia)))\n",
    "    rts = [x[0] for x in L]\n",
    "    # We do not care about accuracy data but, if we did, \n",
    "    # it would be analyzed here.\n",
    "    # ACCs = [x[1] for x in L]\n",
    "    R = np.array(rts)\n",
    "    #print(rts)\n",
    "    D = np.array(person_location_data)\n",
    "    RMSE = np.sqrt(np.mean((D-R)**2))\n",
    "    return(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, here is the RMSE for the value used by John Anderson's classical study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052779941476115956"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fan_rmse(lf = 0.63, mas=1.6, ga=1.0, ia=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is what happens when we pick some other values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.591903996267782"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fan_rmse(lf = 2, mas=0, ga=0, ia=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimization \n",
    "To minimize, we will use Scipy's optimize package and invoke the Nelder-Meade algorithm, which performs gradient descent without needing any information about the function derivatives (which is our case). The first step is to put our function in vector form, which is done by creating a _wrapper_ function that takes the ACT-R parameters as elements of a vector, instead of distinct arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_func(x):\n",
    "    return(fan_rmse(x[0],  # :lf\n",
    "                    x[1],  # :mas\n",
    "                    x[2],  # :ga\n",
    "                    x[3])) # :imaginal-activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to define a vector of initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = np.array([1.0, 1.0, 1.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to define a set of reasonable bounds for each value. For instance, we do not want negative latency factors or spreading activations. Each bound is defined as a `(min, max)` tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(0, 5), (0, 5), (0, 5), (0, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5236946735561773"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_func(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[ 6.16606693e-01,  1.59431959e+00,  1.09249125e+00,\n",
       "        -5.39659632e-04],\n",
       "       [ 6.16613721e-01,  1.59434065e+00,  1.09246312e+00,\n",
       "        -5.39496950e-04],\n",
       "       [ 6.16580047e-01,  1.59428148e+00,  1.09244077e+00,\n",
       "        -5.39268191e-04],\n",
       "       [ 6.16593380e-01,  1.59431944e+00,  1.09247478e+00,\n",
       "        -5.39556676e-04],\n",
       "       [ 6.16607713e-01,  1.59433767e+00,  1.09246559e+00,\n",
       "        -5.39551434e-04]]), array([0.04885864, 0.04885864, 0.04885864, 0.04885864, 0.04885864]))\n",
       "           fun: 0.04885863963176489\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 155\n",
       "           nit: 75\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([ 6.16606693e-01,  1.59431959e+00,  1.09249125e+00, -5.39659632e-04])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(target_func, init, method = \"Nelder-Mead\", options = {\"maxiter\" : 200})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
